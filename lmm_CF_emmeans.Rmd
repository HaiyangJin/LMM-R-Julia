---
title: "Generalized linear mixed-effects modeling of the composite face task"
author: "[Haiyang Jin](https://haiyangjin.github.io/)"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output: 
  html_document:
    code_folding: hide
    number_sections: true
    toc: true
    toc_float: true
---

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r global_options, echo = FALSE, include = FALSE}
options(width = 1500)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      include = TRUE, cache = FALSE, tidy = FALSE, 
                      size = "big", fig.width=8, fig.asp=0.7)
xaringanExtra::use_clipboard()
```

# Preparation
```{r setup, include=FALSE}
library(tidyverse)
library(MASS)
library(lme4)
library(lmerTest)
library(optimx)
library(emmeans)
library(arrow)

# set the contrast coding
options(contrasts = rep("contr.sdif", 2))
```

## Brief introduction
The data were a subset of [one previous study](https://psyarxiv.com/j8g6z/){target="_blank"} where data were analyzed with repeated-measures ANOVA. The independent variables are:
  
+ Condition: monocular (**O**) vs. CFS (**F**)  
+ Congruency: congruent (**C**) vs. incongruent (**I**)  
+ Alignment: aligned (**A**) vs. misaligned (**M**)  
+ answer: same (**S**) vs. different (**D**) (used as `signal` and `noise` in Signal Detection Theory)  

The dependent variables are behavioral responses and response times. Behavioral responses are analyzed with signal detection theory (i.e., generalized linear mixed-effects models with `probit` link). Response times are analyzed with log-normal transformation.

The main research questions are: 
(1) whether there is composite face effect in the `CFS` condition;
(2) whether there is composite face effect in the `monocular` condition;
(3) whether the composite face effect is larger in the `monocular` than the `CFS` condition. 

As discussed [earlier](https://psyarxiv.com/yhmzg/){target="_blank"}, we may claim observing the composite face effect in a particular condition (e.g., `CFS` or `monocular`) only when (1) the performance for aligned faces is better in the congruent relative to the incongruent condition (i.e., `congruent_aligned` > `incongruent_aligned`) and (2) the increased performance in congruent relative to incongruent condition is larger for aligned compared to misaligned faces (i.e., (`congruent_aligned` - `incongruent_aligned`) > (`congruent_misaligned` - `incongruent_misaligned`)). 

Moreover, for the third question, we also need to examine whether the composite effect in the `monocular` condition is larger than that in the `CFS` condition (i.e., [(`monocular_congruent_aligned` - `monocular_incongruent_aligned`) - (`monocular_congruent_misaligned` - `monocular_incongruent_misaligned`)] > [(`CFS_congruent_aligned` - `CFS_incongruent_aligned`) - (`CFS_congruent_misaligned` - `CFS_incongruent_misaligned`)]). 

## Prepare data
Load and set the default levels for the factors:
```{r read the data file}
folder_out <- "output"

df_raw <-  read_csv(file.path("data", "example_data.csv")) %>% 
  mutate(Condition = factor(Condition, levels = c("monocular", "CFS")),
         Congruency = factor(Congruency, levels = c("congruent", "incongruent")),
         Alignment = factor(Alignment, levels = c("aligned", "misaligned")),
         answer = factor(answer, levels = c("same", "different")),
         logRT = log(RT))
head(df_raw)
```

```{r}
# create new variables for each parameter in lmm
df_emm <- df_raw %>% 
  model.matrix(~ Condition * Congruency * Alignment * answer, .) %>% 
  as_tibble() %>% 
  transmute(Cond_main = `ConditionCFS-monocular`,
            Cong_main = `Congruencyincongruent-congruent`,
            Ali_main = `Alignmentmisaligned-aligned`,
            Ans_main = `answerdifferent-same`,
            Cond_Cong = `ConditionCFS-monocular:Congruencyincongruent-congruent`,
            Cond_Ali = `ConditionCFS-monocular:Alignmentmisaligned-aligned`,
            Cong_Ali = `Congruencyincongruent-congruent:Alignmentmisaligned-aligned`,
            Cond_Ans = `ConditionCFS-monocular:answerdifferent-same`,
            Cong_Ans = `Congruencyincongruent-congruent:answerdifferent-same`,
            Ali_Ans = `Alignmentmisaligned-aligned:answerdifferent-same`,
            Cond_Cong_Ali = `ConditionCFS-monocular:Congruencyincongruent-congruent:Alignmentmisaligned-aligned`,
            Cond_Cong_Ans = `ConditionCFS-monocular:Congruencyincongruent-congruent:answerdifferent-same`,
            Cond_Ali_Ans = `ConditionCFS-monocular:Alignmentmisaligned-aligned:answerdifferent-same`,
            Cong_Ali_Ans = `Congruencyincongruent-congruent:Alignmentmisaligned-aligned:answerdifferent-same`,
            Cond_Cong_Ali_Ans = `ConditionCFS-monocular:Congruencyincongruent-congruent:Alignmentmisaligned-aligned:answerdifferent-same`
            ) %>% 
  cbind(df_raw, .) 
```

```{r}
# save data as arrow
# write_arrow(df_emm, file.path("data", "example_sd.arrow"))
```

# Sensitivity d': GLMM with probit link
This section analyzes the behavioral responses with signal detection theory (with `probit` link): `same` and `different` trials are used as `signal` and `noise` to calculate the sensitivity d'.

## Fitting the glmm

### The zero-correlation-parameter model
```{r resp zcp }
file_resp_zcp <- file.path(folder_out, "Resp_lmm_emm_zcp.RData")

# fit the zcp model
if (!file.exists(file_resp_zcp)) {
  glmm_resp_zcp <- glmer(resp ~ Condition * Congruency * Alignment * answer +
                           (Cond_main + Cong_main + Ali_main + Ans_main +
                              Cond_Cong + Cond_Ali + Cong_Ali + Cond_Ans + Cong_Ans + Ali_Ans +
                              Cond_Cong_Ali + Cond_Cong_Ans + Cond_Ali_Ans + Cong_Ali_Ans +
                              Cond_Cong_Ali_Ans || Participant),
                         family = binomial(link = "probit"),
                         data = df_emm,
                         control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                                optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(glmm_resp_zcp, file = file_resp_zcp)
} else {
  load(file_resp_zcp)
}

print(summary(glmm_resp_zcp), corr = FALSE)
```

### The reduced model
```{r PCA analysis for resp zcp lmm }
summary(rePCA(glmm_resp_zcp))
```

Random effect that explained less than 0.1% variances were removed from the zcp model (`glmm_resp_zcp`), leading to the reduced model.

```{r resp rdc }
file_resp_rdc <- file.path(folder_out, "Resp_lmm_emm_rdc.RData")

# fit the rdc model
if (!file.exists(file_resp_rdc)) {
  glmm_resp_rdc <- glmer(resp ~ Condition * Congruency * Alignment * answer +
                           (Cond_main + Cong_main + Ali_main + Ans_main +
                              Cond_Ali + Cond_Ans + Cong_Ans + Ali_Ans + # Cond_Cong + Cong_Ali + 
                              Cond_Cong_Ali + Cong_Ali_Ans # +  Cond_Cong_Ans + Cond_Ali_Ans + 
                            || Participant), # Cond_Cong_Ali_Ans
                         family = binomial(link = "probit"),
                         data = df_emm,
                         control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                                optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(glmm_resp_rdc, file = file_resp_rdc)
} else {
  load(file_resp_rdc)
}

print(summary(glmm_resp_rdc), corr = FALSE)
```

### The extended model
Correlations among random effects are added back to the reduced model (`glmm_resp_rdc`) to create the extended model. 
```{r resp etd }
file_resp_etd <- file.path(folder_out, "Resp_lmm_emm_etd.RData")

# fit the etd model
if (!file.exists(file_resp_etd)) {
  glmm_resp_etd <- glmer(resp ~ Condition * Congruency * Alignment * answer +
                           (Cond_main + Cong_main + Ali_main + Ans_main +
                              Cond_Ali + Cond_Ans + Cong_Ans + Ali_Ans + # Cond_Cong + Cong_Ali + 
                              Cond_Cong_Ali + Cong_Ali_Ans # +  Cond_Cong_Ans + Cond_Ali_Ans + 
                               | Participant), # Cond_Cong_Ali_Ans
                         family = binomial(link = "probit"),
                         data = df_emm,
                         control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                                optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(glmm_resp_etd, file = file_resp_etd)
} else {
  load(file_resp_etd)
}

print(summary(glmm_resp_etd), corr = FALSE)
```

```{r}
summary(rePCA(glmm_resp_etd))
```

Random effect that explained less than 1% variances were removed from the extended model `(glmm_resp_etd)`, leading to another extended model (`glmm_resp_etd1`). (Not quite sure what rule of thumb I should follow to simplify random effects).

```{r resp etd1 }
file_resp_etd1 <- file.path(folder_out, "Resp_lmm_emm_etd1.RData")

# fit the etd1 model
if (!file.exists(file_resp_etd1)) {
  glmm_resp_etd1 <- glmer(resp ~ Condition * Congruency * Alignment * answer +
                           (Ans_main + # Cong_main + Cond_main + Ali_main + 
                              Cond_Ans + # Cond_Cong + Cong_Ali + Cond_Ali + Cong_Ans + Ali_Ans + 
                              Cond_Cong_Ali + Cong_Ali_Ans # +  Cond_Cong_Ans + Cond_Ali_Ans + 
                               | Participant), # Cond_Cong_Ali_Ans
                         family = binomial(link = "probit"),
                         data = df_emm,
                         control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                                optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(glmm_resp_etd1, file = file_resp_etd1)
} else {
  load(file_resp_etd1)
}

print(summary(glmm_resp_etd1), corr = FALSE)

```

```{r}
summary(rePCA(glmm_resp_etd1))
```

Random effect that explained less than 1% variances were removed from the extended model `(glmm_resp_etd1)`, leading to another extended model (`glmm_resp_etd2`). (Not quite sure what rule of thumb I should follow to simplify random effects).

```{r resp etd2 }
file_resp_etd2 <- file.path(folder_out, "Resp_lmm_emm_etd2.RData")

# fit the etd2 model
if (!file.exists(file_resp_etd2)) {
  glmm_resp_etd2 <- glmer(resp ~ Condition * Congruency * Alignment * answer +
                           (0 + Ans_main + # Cong_main + Cond_main + Ali_main + 
                              Cond_Ans + # Cond_Cong + Cong_Ali + Cond_Ali + Cong_Ans + Ali_Ans + 
                              Cong_Ali_Ans # +  Cond_Cong_Ans + Cond_Ali_Ans + Cond_Cong_Ali + 
                               | Participant), # Cond_Cong_Ali_Ans
                         family = binomial(link = "probit"),
                         data = df_emm,
                         control = glmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                                optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(glmm_resp_etd2, file = file_resp_etd2)
} else {
  load(file_resp_etd2)
}

print(summary(glmm_resp_etd2), corr = FALSE)
```

Though `glmm_resp_etd2` does not converge, the `glmm_resp_rdc` already explains the data better (than `glmm_resp_etd2`).

### The optimal model
`glmm_resp_etd2` is compared to `glmm_resp_rdc` and the model that explains data better is used as the optimal model. Follow-up comparisons are based on the optimal model. 
```{r comapre etd and rdc  d}
# compare the extended and reduced model
anova(glmm_resp_etd2, glmm_resp_rdc, refit = FALSE)
```

```{r the optimal model  d}
glmm_resp_opt <- glmm_resp_rdc

print(summary(glmm_resp_opt), corr = FALSE)
```

## Comparisons

```{r}
emm_resp <- emmeans(glmm_resp_opt, ~ Condition * Congruency * Alignment * answer)
```

Sensitivity d' ($Z_{same}$ - $Z_{different}$) in congruent vs. incongruent for aligned faces (i.e., the interaction between Congruency and Answer):
```{r}
# do not need back-transformed
(resp_2inter <- contrast(emm_resp, interaction="pairwise", by = c("Condition", "Alignment"))[c(1,2)])
```

Composite face effect in sensitivity d' (i.e., the interaction between Congruency, Alignment and Answer):
```{r}
# do not need back-transformed
(resp_3inter <- contrast(emm_resp, interaction="pairwise", by = c("Condition"))[c(1,2)])
```

Compare the composite face effect between monocular and CFS conditions:
```{r}
(resp_4inter <- contrast(emm_resp, interaction="pairwise"))
```

## Summary

```{r}
resp_2inter[1]
resp_3inter[1]
```
With the above evidence of responses, we may claim that (1) composite face effect was observed in the monocular condition. 

```{r}
resp_4inter
```
With all above evidence of responses, we may claim (2) the composite face effect was larger in the monocular relative to the CFS condition.


# RT: Lognormal
This sections analyzes response times of correct trials with log-normal transformation.

## Fitting the lmm
### The zero-correlation-parameter model
```{r  rt zcp}
file_rt_zcp <- file.path(folder_out, "RT_lmm_emm_zcp.RData")

# fit the zcp model
if (!file.exists(file_rt_zcp)) {
  lmm_rt_zcp <- lmer(log(RT) ~ Condition * Congruency * Alignment +
                       (Cond_main + Cong_main + Ali_main +
                          Cond_Cong + Cond_Ali + Cong_Ali +
                          Cond_Cong_Ali || Participant),
                     data = filter(df_emm, isCorrect==1),
                     control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(lmm_rt_zcp, file = file_rt_zcp)
} else {
  load(file_rt_zcp)
}

print(summary(lmm_rt_zcp), corr = FALSE)
```

### The reduced model
```{r PCA analysis for rt zcp lmm }
summary(rePCA(lmm_rt_zcp))
```

Random effect that explained less than 0.1% variances are removed from the zcp model (`lmm_rt_zcp`), leading to the reduced model.

```{r  rt rdc}
file_rt_rdc <- file.path(folder_out, "RT_lmm_emm_rdc.RData")

# fit the rdc model
if (!file.exists(file_rt_rdc)) {
  lmm_rt_rdc <- lmer(log(RT) ~ Condition * Congruency * Alignment +
                       (Cond_main + # + Cong_main + Ali_main +
                          Cond_Ali # + Cond_Cong + Cong_Ali +
                        || Participant), # Cond_Cong_Ali 
                     data = filter(df_emm, isCorrect==1),
                     control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(lmm_rt_rdc, file = file_rt_rdc)
} else {
  load(file_rt_rdc)
}

print(summary(lmm_rt_rdc), corr = FALSE)
```

### The extended model
```{r  rt etd}
file_rt_etd <- file.path(folder_out, "RT_lmm_emm_etd.RData")

# fit the etd model
if (!file.exists(file_rt_etd)) {
  lmm_rt_etd <- lmer(log(RT) ~ Condition * Congruency * Alignment +
                       (Cond_main + # + Cong_main + Ali_main +
                          Cond_Ali # + Cond_Cong + Cong_Ali +
                        | Participant), # Cond_Cong_Ali 
                     data = filter(df_emm, isCorrect==1),
                     control = lmerControl(optimizer = "optimx", # calc.derivs = FALSE,
                                           optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE))
  )

  save(lmm_rt_etd, file = file_rt_etd)
} else {
  load(file_rt_etd)
}

print(summary(lmm_rt_etd), corr = FALSE)
```

### The optimal model
`lmm_rt_etd` is compared to `lmm_rt_rdc` and the model that explains data better is used as the optimal model. Follow-up comparisons are based on the optimal model. 
```{r  comapre rt etd and rdc}
# compare the extended and reduced model
anova(lmm_rt_etd, lmm_rt_rdc, refit = FALSE)
```


```{r  the optimal model rt}
lmm_rt_opt <- lmm_rt_rdc

print(summary(lmm_rt_opt), corr = FALSE)
```

## Comparisons
```{r}
emm_rt <- emmeans(lmm_rt_opt, ~ Condition * Congruency * Alignment, lmer.df = "satterthwaite", 
                  pbkrtest.limit = 12800, lmerTest.limit = 12800)
```

Compare congruent vs. incongruent for aligned faces:
```{r}
(rt_sim <- contrast(emm_rt, "pairwise", simple="Congruency")[c(1,2)])
```

Composite face effect of RT (i.e., the interaction between Congruency and Alignment):
```{r}
(rt_2inter <- contrast(emm_rt, interaction="pairwise", by="Condition")[c(1,2)])
```

Compare the composite face effect between monocular and CFS conditions:
```{r}
(rt_3inter <- contrast(emm_rt, interaction="pairwise"))
```

## Summary
With the above evidence of response times, (1) we failed to observe the evidence for composite face effect in any condition. Also, (2) no evidence was found that the composite face effect differed between the monocular and CFS conditions.

# Session information {.unlisted .unnumbered}
```{r}
sessionInfo()
```

